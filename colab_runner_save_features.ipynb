{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlbertoForesti/mldl23-ego/blob/alberto/colab_runner_save_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX7-SVbLTzF8"
      },
      "source": [
        "# Colab Runner for MLDL23-Ego"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EgovisionPolito/mldl23-ego/blob/master/colab_runner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6iYc30HTzGP"
      },
      "source": [
        "## EPIC-Kitchens-55 dataset\n",
        "\n",
        "**READ carefully!**\n",
        "\n",
        "To develop the project, you need to download the RGB frames for a subset of EPIC-Kitchens-55 (participants P08, P01 and P22) from [here](https://politoit-my.sharepoint.com/:f:/g/personal/simone_peirone_polito_it/EqCmaEAi2oBEqEqzBZ-pIA0Bke4EGNkUEhqwApEhUp9tDw?e=DtSbMP) (you need to login with your Polito credentials). \n",
        "\n",
        "You also need to the pretrained checkpoints for each domain from [here](https://politoit-my.sharepoint.com/:f:/g/personal/simone_peirone_polito_it/ErdsZhvmR65Lun5_5O0-l5sBTPjCCZZq2f700Tj_CNzjTQ?e=L1yflf).\n",
        "\n",
        "Upload the dataset on your Google Drive to access it from Google Colab.\n",
        "\n",
        "**NOTE**: As the dataset is quite heavy, we stronly suggest you to implement and test all your code on one for the three dataset. Then, once you are sure everything works, repeat the experiments on the remaining two datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obkaspA1TzGS",
        "outputId": "85ab4b6a-c2a3-48ad-e22d-261d2ad63dc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount google drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ku_Rr6g_TzGY",
        "outputId": "3d323179-5331-47bd-d61d-2b7eee1df597"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/ColabNotebooks/P01.zip\n",
            "  inflating: ./ek_data/P01_01.tar.gz  \n",
            "  inflating: ./ek_data/P01_02.tar.gz  \n",
            "  inflating: ./ek_data/P01_03.tar.gz  \n",
            "  inflating: ./ek_data/P01_04.tar.gz  \n",
            "  inflating: ./ek_data/P01_05.tar.gz  \n",
            "  inflating: ./ek_data/P01_06.tar.gz  \n",
            "  inflating: ./ek_data/P01_07.tar.gz  \n",
            "  inflating: ./ek_data/P01_08.tar.gz  \n",
            "  inflating: ./ek_data/P01_09.tar.gz  \n",
            "  inflating: ./ek_data/P01_10.tar.gz  \n",
            "  inflating: ./ek_data/P01_11.tar.gz  \n",
            "  inflating: ./ek_data/P01_12.tar.gz  \n",
            "  inflating: ./ek_data/P01_13.tar.gz  \n",
            "  inflating: ./ek_data/P01_14.tar.gz  \n",
            "  inflating: ./ek_data/P01_15.tar.gz  \n",
            "  inflating: ./ek_data/P01_16.tar.gz  \n",
            "  inflating: ./ek_data/P01_17.tar.gz  \n",
            "  inflating: ./ek_data/P01_18.tar.gz  \n",
            "  inflating: ./ek_data/P01_19.tar.gz  \n",
            "-rw-r--r-- 1 root root 1.1G Apr 19 07:16 ./ek_data/P01_01.tar.gz\n",
            "-rw-r--r-- 1 root root 390M Apr 19 07:17 ./ek_data/P01_02.tar.gz\n",
            "-rw-r--r-- 1 root root 44M Apr 19 07:17 ./ek_data/P01_03.tar.gz\n",
            "-rw-r--r-- 1 root root 45M Apr 19 07:17 ./ek_data/P01_04.tar.gz\n",
            "-rw-r--r-- 1 root root 420M Apr 19 07:17 ./ek_data/P01_05.tar.gz\n",
            "-rw-r--r-- 1 root root 361M Apr 19 07:17 ./ek_data/P01_06.tar.gz\n",
            "-rw-r--r-- 1 root root 87M Apr 19 07:17 ./ek_data/P01_07.tar.gz\n",
            "-rw-r--r-- 1 root root 57M Apr 19 07:17 ./ek_data/P01_08.tar.gz\n",
            "-rw-r--r-- 1 root root 1.7G Apr 19 07:18 ./ek_data/P01_09.tar.gz\n",
            "-rw-r--r-- 1 root root 90M Apr 19 07:18 ./ek_data/P01_10.tar.gz\n",
            "-rw-r--r-- 1 root root 355M Apr 19 07:18 ./ek_data/P01_11.tar.gz\n",
            "-rw-r--r-- 1 root root 88M Apr 19 07:18 ./ek_data/P01_12.tar.gz\n",
            "-rw-r--r-- 1 root root 42M Apr 19 07:18 ./ek_data/P01_13.tar.gz\n",
            "-rw-r--r-- 1 root root 825M Apr 19 07:18 ./ek_data/P01_14.tar.gz\n",
            "-rw-r--r-- 1 root root 728M Apr 19 07:18 ./ek_data/P01_15.tar.gz\n",
            "-rw-r--r-- 1 root root 92M Apr 19 07:18 ./ek_data/P01_16.tar.gz\n",
            "-rw-r--r-- 1 root root 739M Apr 19 07:19 ./ek_data/P01_17.tar.gz\n",
            "-rw-r--r-- 1 root root 1.9G Apr 19 07:19 ./ek_data/P01_18.tar.gz\n",
            "-rw-r--r-- 1 root root 375M Apr 19 07:20 ./ek_data/P01_19.tar.gz\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "# As read and write operations from google drive are slow, we suggest to copy and unzip\n",
        "# the dataset in a local directory on the Colab's machine.\n",
        "mkdir -p ek_data/frames\n",
        "\n",
        "# Copy the *.tar.gz files of Epic-Kitchens\n",
        "# TODO: replace with your path\n",
        "\n",
        "path=/content/drive/MyDrive/ColabNotebooks/P01.zip\n",
        "\n",
        "unzip $path -d ./ek_data\n",
        "\n",
        "# Untar\n",
        "for file in ./ek_data/*.tar.gz; do\n",
        "  fn=$(basename $file)\n",
        "  fn=${fn/.tar.gz/}\n",
        "  ls -lah $file\n",
        "  mkdir -p ek_data/frames/$fn\n",
        "  tar xf $file --directory=ek_data/frames/$fn\n",
        "done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ou29vvgYTzGb"
      },
      "source": [
        "## Running the code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfxNEJA1dbLD"
      },
      "outputs": [],
      "source": [
        "# Install conda on Google Colab\n",
        "\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9TB8gMAdoWt"
      },
      "outputs": [],
      "source": [
        "# Create a conda environment \n",
        "!conda env create --name egovision -f mldl23-ego/requirements.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anyDvNXeTzGk"
      },
      "source": [
        "**TIP**: As the creation of the Conda Environment may be a slow process, you may look at the `conda-pack` package to store the environment in a .tar.gz archive you can store on Google Drive and restore later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31xCeYMnc67M"
      },
      "outputs": [],
      "source": [
        "# Clone the public repository (or your repository)\n",
        "%%bash\n",
        "rm -r mldl23-ego\n",
        "git clone --branch alberto --single-branch https://github.com/AlbertoForesti/mldl23-ego mldl23-ego\n",
        "cp -r /content/drive/MyDrive/ColabNotebooks/saved_models mldl23-ego/saved_models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BkWmUn_TzGm"
      },
      "source": [
        "## Features extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88YghJyXhbfS"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "cd mldl23-ego\n",
        "\n",
        "PYTHON_PATH=/usr/local/envs/egovision/bin/python\n",
        "$PYTHON_PATH save_feat.py name=change_me \\\n",
        "  config=configs/I3D_save_feat.yaml \\\n",
        "  dataset.shift=D2-D2 \\\n",
        "  dataset.RGB.data_path=../ek_data/frames \\\n",
        "  split=train"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "aml22",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "2fc1f0eeae38a5df67b0f713e03196095ce1bfa55aa551576e8e58c2ba904c5a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}